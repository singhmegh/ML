{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03425f78-f3b3-4c5e-82af-381b07726c88",
   "metadata": {},
   "source": [
    "# Object Tracking & detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72cce523-538c-4d63-9606-4827d3f8d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a77eb2-79ad-4fa9-906d-a5b8fb267c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"D:/c data/cvimg/mixkit-man-and-woman-jogging-together-on-the-street-40881-hd-ready.mp4\")\n",
    "r,f = cap.read()\n",
    "x,y,w,h = 290,55,250,885                                                                # ROI (Region of Interest):where the object is located in the first frame.\n",
    "t = (x,y,w,h)                                                                           # track mai daaldiya\n",
    "roi = f[y:y+h,x:x+w]\n",
    "hsv_roi = cv2.cvtColor(roi,cv2.COLOR_BGR2HSV)                                           # convert it into HSV cause HSV is better for color tracking\n",
    "mask = cv2.inRange(hsv_roi,np.array((0.,60.,32.)),np.array((180.,255.,255.,)))          # masking ki range function ke through\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])                               # histogram color ke through filter kiya.\n",
    "                                                                                        # This histogram represents the color distribution of the object you want to trac\n",
    "#Normalize the window\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)                                  # normalize kiya for stablity\n",
    "tr = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT , 10,1 )                          # Defines termination criteria for the MeanShift algorithm:\n",
    "\n",
    "while cap.isOpened():\n",
    "    r,f = cap.read()\n",
    "    if r == True:\n",
    "        hsv_f = cv2.cvtColor(f , cv2.COLOR_BGR2HSV)\n",
    "        d = cv2.calcBackProject([hsv_f],[0],roi_hist,[0,180],1)                         # backpropogation ke through vedio track ki \n",
    "        r,tp = cv2.meanShift(d,t,tr)                                                    # meanshift:object ke movement ke sath shift hoga , camshift: change shape according to object \n",
    "        x,y,w,h = tp\n",
    "        final = cv2.rectangle(f,(x,y),(x+w,y+h),(0,0,255),4)\n",
    "        cv2.imshow(\"org\",f)\n",
    "        if cv2.waitKey(25) & 0xff == ord(\"p\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ba39fd-6ef1-46eb-a3d9-a60ecce28223",
   "metadata": {},
   "source": [
    "# Corner detection using detection method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0331280-37be-46a8-a472-f7057536e0b1",
   "metadata": {},
   "source": [
    "# via Harris Corner Detection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6667f9c-3d8f-4e22-bed2-1eb093617cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"D:/c data/cvimg/shapes.png\") \n",
    "gr = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#print(gr)\n",
    "\n",
    "# convert interger into float32 bits \n",
    "gr = np.float32(gr)\n",
    "\n",
    "res = cv2.cornerHarris(gr,3,5,0.04)\n",
    "\n",
    "res = cv2.dilate(res,None)\n",
    "img[res>0.01*res.max()] = [0,0,255]\n",
    "\n",
    "cv2.imshow(\"org\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76a57516-fdf9-439c-84e4-21f868fe2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"D:/c data/cvimg/green.jpeg\")\n",
    "gr = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# convert interger into float32 bits \n",
    "gr = np.float32(gr)\n",
    "\n",
    "res = cv2.cornerHarris(gr,2,3,0.04)\n",
    "\n",
    "res = cv2.dilate(res,None)\n",
    "img[res>0.01*res.max()] = [0,0,255]\n",
    "\n",
    "cv2.imshow(\"org\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150cd43e-105b-4642-a3c4-463c40e31254",
   "metadata": {},
   "source": [
    "# Shi -Tomasi corner detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "518d058e-0788-4541-941c-cf6e5f9ae2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"D:/c data/cvimg/shapes.png\") \n",
    "gr = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cr = cv2.goodFeaturesToTrack(gr,36,0.01,20)\n",
    "cr = np.int64(cr)\n",
    "\n",
    "for i in cr:\n",
    "    x,y = i.ravel()\n",
    "    cv2.circle(img,(x,y),5,(0,0,255),-1)\n",
    "\n",
    "cv2.imshow(\"org\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e87b72-fc03-45ab-b9aa-7e8ac0d11750",
   "metadata": {},
   "source": [
    "# object detection using Haar-Cascade  (Face Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a154463-9dcb-4520-a68d-518471689414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[175  39  26  26]\n",
      " [ 68  39  28  28]\n",
      " [  7  22  31  31]\n",
      " [ 98  42  25  25]\n",
      " [240  30  27  27]\n",
      " [134  31  30  30]\n",
      " [202  35  29  29]\n",
      " [ 70  20  39  39]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"D:/c data/cvimg/group.jpeg\")\n",
    "gry = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "f = cv2.CascadeClassifier(\"C:/Users/sumit/AppData/Local/Programs/Python/Python313/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml\")\n",
    "d = f.detectMultiScale(gry,1.1,2)         #it give you a points\n",
    "print(d)\n",
    "\n",
    "for (x,y,w,h) in d:\n",
    "     cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),3)\n",
    "\n",
    "\n",
    "cv2.imshow(\"org\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3613b107-8519-46a8-bb33-7a01a532151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(cv2.data.haarcascades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13553fd6-66ec-43a4-ad4c-06af76167829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[202   7  61  61]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"D:/c data/cvimg/dog mann.jfif\")\n",
    "gry = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "f = cv2.CascadeClassifier(\"C:/Users/sumit/AppData/Local/Programs/Python/Python313/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml\")\n",
    "d = f.detectMultiScale(gry,1.6,2)         #it give you a points\n",
    "print(d)\n",
    "\n",
    "for (x,y,w,h) in d:\n",
    "     cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),3)\n",
    "\n",
    "\n",
    "cv2.imshow(\"org\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dea638-62f8-40aa-9141-a41fdcae1a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
