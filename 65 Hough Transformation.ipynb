{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c12c4e4-fe23-4662-9121-d01938970ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ff708f9-5ccd-4f72-805a-a792fccbc65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"D:/c data/cvimg/sudoku.png\")\n",
    "img = cv2.resize(img,(400,400))\n",
    "\n",
    "gry = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)          #Hough Line Transform works best on single-channel images.\n",
    "edg = cv2.Canny(gry,20,250)                         #Uses Canny Edge Detector.,Thresholds are 20 (low) and 250 (high).\n",
    "\n",
    "lines = cv2.HoughLines(edg,1,np.pi/180,200)         #1 → resolution of rho (distance from origin to line) = 1 pixel.,np.pi/180 → resolution of theta (angle step) = 1 degree.\n",
    "\n",
    "for r,th in lines[0]:\n",
    "    a = np.cos(th)\n",
    "    b = np.sin(th)\n",
    "\n",
    "    x0 = a*r\n",
    "    y0 = b*r\n",
    "\n",
    "    x1 = int(x0+1000*(-b))                      #1000? → It’s just a large number, ensures the line extends outside the image size.\n",
    "    y1 = int(x0+1000*(a))\n",
    "    x2 = int(x0-1000*(-b))\n",
    "    y2 = int(x0-1000*(a))\n",
    "\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "\n",
    "cv2.imshow(\"org\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b228618-c707-434c-8796-6c5b1fd6d2ef",
   "metadata": {},
   "source": [
    "# shortest method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2791ed84-e00b-44d6-adb0-a07c328c3a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"D:/c data/cvimg/sudoku.png\")\n",
    "img = cv2.resize(img,(400,400))\n",
    "\n",
    "gry = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)          \n",
    "edg = cv2.Canny(gry,20,250)\n",
    "\n",
    "l = cv2.HoughLinesP(edg,1,np.pi/180,200,minLineLength = 180,maxLineGap = 100)\n",
    "\n",
    "for i in l:\n",
    "    x1,y1,x2,y2 = i[0]\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "\n",
    "cv2.imshow(\"org\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767f1bec-7014-443e-a0d2-09bdef67af73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76bcf463-e500-470d-b6fb-dfc6e5c95624",
   "metadata": {},
   "source": [
    "# Template Matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f676777c-99ed-4671-88af-405c7db6183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"D:/c data/cvimg/group.jpeg\")\n",
    "gry = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "tmp = cv2.imread(\"D:/c data/cvimg/group_copy1.jpeg\")\n",
    "gry1= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "w,h = gry1.shape[1],gry1.shape[0]\n",
    "\n",
    "res = cv2.matchTemplate(gry,gry1,cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "thr = 0.99\n",
    "\n",
    "l = np.where(res>=thr)\n",
    "\n",
    "for i in zip(*l[::-1]):\n",
    "    cv2.rectangle(img,i,(i[0]+w,i[1]+h),(0,0,255),2)\n",
    "\n",
    "#print(gry1.shape)\n",
    "#cv2.imshow(\"res\",res)\n",
    "img = cv2.resize(img,(600,600))\n",
    "cv2.imshow(\"org\",img)\n",
    "cv2.imshow(\"tmp\",tmp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a99a2f-7b36-4280-9f74-0ddc51af7db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "355e3111-58f4-4ece-8bdf-5a34cded3666",
   "metadata": {},
   "source": [
    "# hough circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "174553ee-c0a8-42dd-8b92-94235f6730e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"D:/c data/cvimg/ball.png\")\n",
    "gry = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "gry = cv2.medianBlur(gry,5)\n",
    "\n",
    "c = cv2.HoughCircles(gry,cv2.HOUGH_GRADIENT,1,20,param1 = 90 ,param2 = 80,minRadius = 0,maxRadius=0)\n",
    "\n",
    "data = np.uint16(np.around(c))\n",
    "\n",
    "for (x,y,r) in data [0,:]:\n",
    "    cv2.circle(img,(x,y),r,(0,0,255),2)\n",
    "\n",
    "cv2.imshow(\"org\",gry)\n",
    "cv2.imshow(\"Circle\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dff720-6a84-4693-9be7-1e6201758977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8b65a83-b401-429d-99c4-c3cb2932567e",
   "metadata": {},
   "source": [
    "# Grabcut algo for background change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95e2ee5e-170c-4c0e-8200-261d4e7357c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"D:/c data/cvimg/grabcut.jfif\")\n",
    "\n",
    "mask1 = np.zeros(img.shape[:2],np.uint8)\n",
    "\n",
    "bgmask = np.zeros((1,65),np.float64)*255                               # background mask\n",
    "fgmask = np.zeros((1,65),np.float64)*255                               # foreground mask\n",
    "\n",
    "# [x1,y1,x2,y2]\n",
    "r = [21,63,267,168]\n",
    "cv2.grabCut(img,mask1,r,bgmask,fgmask,10,cv2.GC_INIT_WITH_RECT)        #cv2.GC_INIT_WITH_RECT = tells GrabCut to initialize with rectangle\n",
    "\n",
    "mask2 = np.where((mask1 == 2 )|(mask1 == 0),0,1).astype(\"uint8\")       #(mask1 == 2) -> creates a Boolean array (True where pixel is 2, else False).\n",
    "\n",
    "                                                                        #(mask1 == 0) → Boolean array (True where pixel is 0).\n",
    "\n",
    "                                                                        # | (bitwise OR) → combines the two conditions.\n",
    "img = img*mask2[:,:,np.newaxis]\n",
    "\n",
    "cv2.imshow(\"org\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34d17cb-48ef-45b3-8664-d329d097e6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e832226b-5c37-4a67-9902-3a86b45e883a",
   "metadata": {},
   "source": [
    "# vedio bg removal by using algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d7a9585-b00d-4318-a518-5d0981a0c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"D:/c data/cvimg/Screen Recording 2025-07-31 224915.mp4\")\n",
    "\n",
    "algo1 = cv2.createBackgroundSubtractorKNN()\n",
    "algo2 = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while True:\n",
    "    r,f = cap.read()\n",
    "    if r == True:\n",
    "        f = cv2.resize(f,(500,400))\n",
    "        r1 = algo1.apply(f)\n",
    "        r2 = algo2.apply(f)\n",
    "        cv2.imshow(\"algo1\",r1)\n",
    "        cv2.imshow(\"algo2\",r2)\n",
    "        cv2.imshow(\"org\",f)\n",
    "        if cv2.waitKey(40) & 0xff == ord(\"p\"):\n",
    "             break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eb62c3-b842-44a9-8bcf-9f51e27fe9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
